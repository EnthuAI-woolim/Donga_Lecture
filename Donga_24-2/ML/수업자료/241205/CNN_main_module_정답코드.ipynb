{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8CW-ldez0bV"
      },
      "source": [
        "## 패키지 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y9SBNBvz989"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.datasets as dataset\n",
        "import torchvision.transforms as transform\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIZvkTTVz_We"
      },
      "source": [
        "## Dataset 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22hst1Gx0DPK"
      },
      "outputs": [],
      "source": [
        "# Training dataset 다운로드\n",
        "cifar10_train = dataset.CIFAR10(root = \"./\", # 데이터셋을 저장할 위치\n",
        "                            train = True,\n",
        "                            transform = transform.ToTensor(),\n",
        "                            download = True)\n",
        "# Testing dataset 다운로드\n",
        "cifar10_test = dataset.CIFAR10(root = \"./\",\n",
        "                            train = False,\n",
        "                            transform = transform.ToTensor(),\n",
        "                            download = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARS1c9CD0ElD"
      },
      "source": [
        "## CIFAR10 데이터셋 형상 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZdigwTg0GnB"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "print(len(cifar10_train))     # training dataset 개수 확인\n",
        "\n",
        "first_data = cifar10_train[1]\n",
        "print(first_data[0].shape)  # 두번째 data의 형상 확인\n",
        "print(first_data[1])        # 두번째 data의 정답 확인\n",
        "\n",
        "\n",
        "plt.imshow(first_data[0].permute(1, 2, 0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOCujlwh0TJw"
      },
      "source": [
        "## VGG Net 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3LB6Iv-0U56"
      },
      "outputs": [],
      "source": [
        "class VGG (nn.Module):\n",
        "  def __init__ (self):\n",
        "    super(VGG, self).__init__()\n",
        "\n",
        "    self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)    # Convolution: [3x3x3] x 16, s1, p1\n",
        "    self.conv1_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)   # Convolution: [3x3x16] x 32, s1, p1\n",
        "\n",
        "    self.conv2_1 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)   # Convolution: [3x3x32] x 32, s1, p1\n",
        "    self.conv2_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)   # Convolution: [3x3x64] x 64, s1, p1\n",
        "\n",
        "    self.conv3_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)  # Convolution: [3x3x64] x 128, s1, p1\n",
        "    self.conv3_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1) # Convolution: [3x3x128] x 256, s1, p1\n",
        "\n",
        "    self.fc1 = nn.Linear(4096, 512)   # Fully connected layer: 4096 x 512\n",
        "    self.fc2 = nn.Linear(512, 256)    # Fully connected layer: 512 x 256\n",
        "    self.fc3 = nn.Linear(256, 10)     # Fully connected layer: 256 x 10\n",
        "\n",
        "    # 파라미터를 가지지 않은 layer는 한 번만 선언해도 문제 없음\n",
        "    self.relu = nn.ReLU()\n",
        "    self.avgPool2d = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # convolution layers\n",
        "    out = self.relu(self.conv1_1(x))\n",
        "    out = self.relu(self.conv1_2(out))\n",
        "    out = self.avgPool2d(out)\n",
        "\n",
        "    out = self.relu(self.conv2_1(out))\n",
        "    out = self.relu(self.conv2_2(out))\n",
        "    out = self.avgPool2d(out)\n",
        "\n",
        "    out = self.relu(self.conv3_1(out))\n",
        "    out = self.relu(self.conv3_2(out))\n",
        "    out = self.avgPool2d(out)\n",
        "\n",
        "    # 평탄화\n",
        "    out = out.reshape(-1, 4096)\n",
        "\n",
        "    # fully connected layers\n",
        "    out = self.relu(self.fc1(out))\n",
        "    out = self.relu(self.fc2(out))\n",
        "    out = self.fc3(out)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltAhcjO60b0x"
      },
      "source": [
        "## Hyper-parameters 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1INfQRt0eJm"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "training_epochs = 20\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "network = VGG()\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr = learning_rate)\n",
        "data_loader = DataLoader(dataset=cifar10_train,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True,\n",
        "                         drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfy95Byn0f1E"
      },
      "source": [
        "## 학습을 위한 반복문 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEngtl0a0hFs"
      },
      "outputs": [],
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda:0'\n",
        "\n",
        "network = network.to(device)\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "  total_batch = len(data_loader)\n",
        "\n",
        "  for img, label in data_loader:\n",
        "\n",
        "    img = img.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    pred = network(img)\n",
        "\n",
        "    loss = loss_function(pred, label)\n",
        "    optimizer.zero_grad() # gradient 초기화\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += loss / total_batch\n",
        "\n",
        "  print('Epoch: %d Loss = %f'%(epoch+1, avg_cost))\n",
        "\n",
        "print('Learning finished')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UeKYHAz1NdM"
      },
      "source": [
        "## 학습이 완료된 모델을 이용해 정답률 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AoZ9Dmh1Pxj"
      },
      "outputs": [],
      "source": [
        "network = network.to('cpu')\n",
        "with torch.no_grad(): # test에서는 기울기 계산 제외\n",
        "\n",
        "  img_test = torch.tensor(np.transpose(cifar10_test.data, (0, 3, 1, 2)))/255.\n",
        "  label_test = torch.tensor(cifar10_test.targets)\n",
        "\n",
        "  prediction = network(img_test) # 전체 test data를 한번에 계산\n",
        "\n",
        "  correct_prediction = torch.argmax(prediction, 1) == label_test\n",
        "  accuracy = correct_prediction.float().mean()\n",
        "  print('Accuracy:', accuracy.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZmsmIJpC4Xy"
      },
      "source": [
        "## -----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUYfK3LVEDvm"
      },
      "source": [
        "## Model architecture 구성 실습 (ResNet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VotA21Y3EKLh"
      },
      "source": [
        "## 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyEDRgOoELTR"
      },
      "outputs": [],
      "source": [
        "class ResNet (nn.Module):\n",
        "  def __init__ (self):\n",
        "    super(ResNet, self).__init__()\n",
        "\n",
        "    self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)    # Convolution: [3x3x3] x 16, s1, p1\n",
        "    self.conv1_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)   # Convolution: [3x3x16] x 32, s1, p1\n",
        "\n",
        "    self.conv2_1 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)   # Convolution: [3x3x32] x 32, s1, p1\n",
        "    self.conv2_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)   # Convolution: [3x3x64] x 64, s1, p1\n",
        "\n",
        "    self.conv3_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)  # Convolution: [3x3x64] x 128, s1, p1\n",
        "    self.conv3_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1) # Convolution: [3x3x128] x 256, s1, p1\n",
        "\n",
        "    self.fc1 = nn.Linear(4096, 512)   # Fully connected layer: 4096 x 512\n",
        "    self.fc2 = nn.Linear(512, 256)    # Fully connected layer: 512 x 256\n",
        "    self.fc3 = nn.Linear(256, 10)     # Fully connected layer: 256 x 10\n",
        "\n",
        "    # 파라미터를 가지지 않은 layer는 한 번만 선언해도 문제 없음\n",
        "    self.relu = nn.ReLU()\n",
        "    self.avgPool2d = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    # skip connection\n",
        "    self.conv_skip1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.conv_skip2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.conv_skip3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # convolution layers\n",
        "    input_feature = x\n",
        "    out = self.relu(self.conv1_1(x))\n",
        "    out = self.relu(self.conv1_2(out))\n",
        "\n",
        "    skip = self.conv_skip1(input_feature)\n",
        "    out = out + skip\n",
        "\n",
        "    out = self.avgPool2d(out)\n",
        "\n",
        "    input_feature = out\n",
        "\n",
        "    out = self.relu(self.conv2_1(out))\n",
        "    out = self.relu(self.conv2_2(out))\n",
        "\n",
        "    skip = self.conv_skip2(input_feature)\n",
        "    out = out + skip\n",
        "\n",
        "    out = self.avgPool2d(out)\n",
        "\n",
        "    out = self.relu(self.conv3_1(out))\n",
        "    out = self.relu(self.conv3_2(out))\n",
        "    out = self.avgPool2d(out)\n",
        "\n",
        "    # 평탄화\n",
        "    out = out.reshape(-1, 4096)\n",
        "\n",
        "    # fully connected layers\n",
        "    out = self.relu(self.fc1(out))\n",
        "    out = self.relu(self.fc2(out))\n",
        "    out = self.fc3(out)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFujRpv4ESAR"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6fhVYoiES7d"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters 지정\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "training_epochs = 20\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "network = ResNet()\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr = learning_rate)\n",
        "data_loader = DataLoader(dataset=cifar10_train,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True,\n",
        "                         drop_last=True)\n",
        "\n",
        "# 학습을 위한 반복문 진행\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda:0'\n",
        "\n",
        "network = network.to(device)\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "  total_batch = len(data_loader)\n",
        "\n",
        "  for img, label in data_loader:\n",
        "\n",
        "    img = img.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    pred = network(img)\n",
        "\n",
        "    loss = loss_function(pred, label)\n",
        "    optimizer.zero_grad() # gradient 초기화\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += loss / total_batch\n",
        "\n",
        "  print('Epoch: %d Loss = %f'%(epoch+1, avg_cost))\n",
        "\n",
        "print('Learning finished')\n",
        "\n",
        "# 정답률 확인\n",
        "network = network.to('cpu')\n",
        "with torch.no_grad(): # test에서는 기울기 계산 제외\n",
        "\n",
        "  img_test = torch.tensor(np.transpose(cifar10_test.data, (0, 3, 1, 2)))/255.\n",
        "  label_test = torch.tensor(cifar10_test.targets)\n",
        "\n",
        "  prediction = network(img_test) # 전체 test data를 한번에 계산\n",
        "\n",
        "  correct_prediction = torch.argmax(prediction, 1) == label_test\n",
        "  accuracy = correct_prediction.float().mean()\n",
        "  print('Accuracy:', accuracy.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abZJhykEC4Xz"
      },
      "source": [
        "## -----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhA7jSSSC4Xz"
      },
      "source": [
        "## Model architecture 구성 실습 (DenseNet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9VWgCDiC4Xz"
      },
      "source": [
        "## 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l9ZARdLC4Xz"
      },
      "outputs": [],
      "source": [
        "class DenseNet(nn.Module):\n",
        "  def __init__ (self):\n",
        "    super(DenseNet, self).__init__()\n",
        "\n",
        "    self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)    # Convolution: [3x3x3] x 16, s1, p1\n",
        "    self.conv1_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)   # Convolution: [3x3x16] x 32, s1, p1\n",
        "\n",
        "    self.conv2_1 = nn.Conv2d(in_channels=35, out_channels=32, kernel_size=3, padding=1)   # Convolution: [3x3x32] x 32, s1, p1\n",
        "    self.conv2_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)   # Convolution: [3x3x64] x 64, s1, p1\n",
        "\n",
        "    self.conv3_1 = nn.Conv2d(in_channels=99, out_channels=128, kernel_size=3, padding=1)  # Convolution: [3x3x64] x 128, s1, p1\n",
        "    self.conv3_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1) # Convolution: [3x3x128] x 256, s1, p1\n",
        "\n",
        "    self.fc1 = nn.Linear(4096, 512)   # Fully connected layer: 4096 x 512\n",
        "    self.fc2 = nn.Linear(512, 256)    # Fully connected layer: 512 x 256\n",
        "    self.fc3 = nn.Linear(256, 10)     # Fully connected layer: 256 x 10\n",
        "\n",
        "    # 파라미터를 가지지 않은 layer는 한 번만 선언해도 문제 없음\n",
        "    self.relu = nn.ReLU()\n",
        "    self.avgPool2d = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # convolution layers\n",
        "    input_feature = x\n",
        "    out = self.relu(self.conv1_1(x))\n",
        "    out = self.relu(self.conv1_2(out))\n",
        "\n",
        "    out = torch.cat([out, input_feature], dim=1)\n",
        "    out = self.avgPool2d(out)\n",
        "\n",
        "    input_feature = out\n",
        "\n",
        "    out = self.relu(self.conv2_1(out))\n",
        "    out = self.relu(self.conv2_2(out))\n",
        "\n",
        "    out = torch.cat([out, input_feature], dim=1)\n",
        "    out = self.avgPool2d(out)\n",
        "\n",
        "    out = self.relu(self.conv3_1(out))\n",
        "    out = self.relu(self.conv3_2(out))\n",
        "    out = self.avgPool2d(out)\n",
        "\n",
        "    # 평탄화\n",
        "    out = out.reshape(-1, 4096)\n",
        "\n",
        "    # fully connected layers\n",
        "    out = self.relu(self.fc1(out))\n",
        "    out = self.relu(self.fc2(out))\n",
        "    out = self.fc3(out)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vmkTfuqC4Xz"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM4gUctSC4Xz"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters 지정\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "training_epochs = 20\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "network = DenseNet()\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr = learning_rate)\n",
        "data_loader = DataLoader(dataset=cifar10_train,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True,\n",
        "                         drop_last=True)\n",
        "\n",
        "# 학습을 위한 반복문 진행\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda:0'\n",
        "\n",
        "network = network.to(device)\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "  total_batch = len(data_loader)\n",
        "\n",
        "  for img, label in data_loader:\n",
        "\n",
        "    img = img.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    pred = network(img)\n",
        "\n",
        "    loss = loss_function(pred, label)\n",
        "    optimizer.zero_grad() # gradient 초기화\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += loss / total_batch\n",
        "\n",
        "  print('Epoch: %d Loss = %f'%(epoch+1, avg_cost))\n",
        "\n",
        "print('Learning finished')\n",
        "\n",
        "# 정답률 확인\n",
        "network = network.to('cpu')\n",
        "with torch.no_grad(): # test에서는 기울기 계산 제외\n",
        "\n",
        "  img_test = torch.tensor(np.transpose(cifar10_test.data, (0, 3, 1, 2)))/255.\n",
        "  label_test = torch.tensor(cifar10_test.targets)\n",
        "\n",
        "  prediction = network(img_test) # 전체 test data를 한번에 계산\n",
        "\n",
        "  correct_prediction = torch.argmax(prediction, 1) == label_test\n",
        "  accuracy = correct_prediction.float().mean()\n",
        "  print('Accuracy:', accuracy.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcw3JPSIC4Xz"
      },
      "source": [
        "## -----------------------------------------------------------------:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_NvIQOoC4Xz"
      },
      "source": [
        "## Model architecture 구성 실습 (SENet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sb7wm5vC4Xz"
      },
      "source": [
        "## 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z772aqcGC4Xz"
      },
      "outputs": [],
      "source": [
        "class SENet (nn.Module):\n",
        "  def __init__ (self):\n",
        "    super(SENet, self).__init__()\n",
        "\n",
        "    self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)    # Convolution: [3x3x3] x 16, s1, p1\n",
        "    self.conv1_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)   # Convolution: [3x3x16] x 32, s1, p1\n",
        "\n",
        "    self.conv2_1 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)   # Convolution: [3x3x32] x 32, s1, p1\n",
        "    self.conv2_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)   # Convolution: [3x3x64] x 64, s1, p1\n",
        "\n",
        "    self.conv3_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)  # Convolution: [3x3x64] x 128, s1, p1\n",
        "    self.conv3_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1) # Convolution: [3x3x128] x 256, s1, p1\n",
        "\n",
        "    self.fc1 = nn.Linear(4096, 512)   # Fully connected layer: 4096 x 512\n",
        "    self.fc2 = nn.Linear(512, 256)    # Fully connected layer: 512 x 256\n",
        "    self.fc3 = nn.Linear(256, 10)     # Fully connected layer: 256 x 10\n",
        "\n",
        "    # 파라미터를 가지지 않은 layer는 한 번만 선언해도 문제 없음\n",
        "    self.relu = nn.ReLU()\n",
        "    self.avgPool2d = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    # channel attention\n",
        "    self.adaptivePool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.caconv1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1)\n",
        "    self.caconv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # convolution layers\n",
        "    out = self.relu(self.conv1_1(x))\n",
        "    out = self.relu(self.conv1_2(out))\n",
        "    out = self.avgPool2d(out)\n",
        "\n",
        "    out = self.relu(self.conv2_1(out))\n",
        "    out = self.relu(self.conv2_2(out))\n",
        "    out = self.avgPool2d(out)\n",
        "\n",
        "    ca_out = self.adaptivePool(out)\n",
        "    ca_out = self.caconv1(ca_out)\n",
        "    ca_out = self.relu(ca_out)\n",
        "    ca_out = self.caconv2(ca_out)\n",
        "    ca_out = self.sigmoid(ca_out)\n",
        "    ca_out = ca_out.expand_as(out)\n",
        "    out = out * ca_out\n",
        "\n",
        "    out = self.relu(self.conv3_1(out))\n",
        "    out = self.relu(self.conv3_2(out))\n",
        "    out = self.avgPool2d(out)\n",
        "\n",
        "    # 평탄화\n",
        "    out = out.reshape(-1, 4096)\n",
        "\n",
        "    # fully connected layers\n",
        "    out = self.relu(self.fc1(out))\n",
        "    out = self.relu(self.fc2(out))\n",
        "    out = self.fc3(out)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2nqcl48C4Xz"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S52rpsnC4Xz"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters 지정\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "training_epochs = 20\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "network = SENet()\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr = learning_rate)\n",
        "data_loader = DataLoader(dataset=cifar10_train,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True,\n",
        "                         drop_last=True)\n",
        "\n",
        "# 학습을 위한 반복문 진행\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda:0'\n",
        "\n",
        "network = network.to(device)\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "  total_batch = len(data_loader)\n",
        "\n",
        "  for img, label in data_loader:\n",
        "\n",
        "    img = img.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    pred = network(img)\n",
        "\n",
        "    loss = loss_function(pred, label)\n",
        "    optimizer.zero_grad() # gradient 초기화\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += loss / total_batch\n",
        "\n",
        "  print('Epoch: %d Loss = %f'%(epoch+1, avg_cost))\n",
        "\n",
        "print('Learning finished')\n",
        "\n",
        "# 정답률 확인\n",
        "network = network.to('cpu')\n",
        "with torch.no_grad(): # test에서는 기울기 계산 제외\n",
        "\n",
        "  img_test = torch.tensor(np.transpose(cifar10_test.data, (0, 3, 1, 2)))/255.\n",
        "  label_test = torch.tensor(cifar10_test.targets)\n",
        "\n",
        "  prediction = network(img_test) # 전체 test data를 한번에 계산\n",
        "\n",
        "  correct_prediction = torch.argmax(prediction, 1) == label_test\n",
        "  accuracy = correct_prediction.float().mean()\n",
        "  print('Accuracy:', accuracy.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## -----------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "VsemuFHMr8w5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model architecture 구성 실습 (조합 실험)"
      ],
      "metadata": {
        "id": "D_fd4vZZsBVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CombiNet (nn.Module):\n",
        "  def __init__ (self):\n",
        "    super(CombiNet, self).__init__()\n",
        "\n",
        "    self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)    # Convolution: [3x3x3] x 16, s1, p1\n",
        "    self.conv1_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)   # Convolution: [3x3x16] x 32, s1, p1\n",
        "\n",
        "    self.conv2_1 = nn.Conv2d(in_channels=35, out_channels=32, kernel_size=3, padding=1)   # Convolution: [3x3x32] x 32, s1, p1\n",
        "    self.conv2_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)   # Convolution: [3x3x64] x 64, s1, p1\n",
        "\n",
        "    self.conv3_1 = nn.Conv2d(in_channels=99, out_channels=128, kernel_size=3, padding=1)  # Convolution: [3x3x64] x 128, s1, p1\n",
        "    self.conv3_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1) # Convolution: [3x3x128] x 256, s1, p1\n",
        "\n",
        "    self.fc1 = nn.Linear(4096, 512)   # Fully connected layer: 4096 x 512\n",
        "    self.fc2 = nn.Linear(512, 256)    # Fully connected layer: 512 x 256\n",
        "    self.fc3 = nn.Linear(256, 10)     # Fully connected layer: 256 x 10\n",
        "\n",
        "    # 파라미터를 가지지 않은 layer는 한 번만 선언해도 문제 없음\n",
        "    self.relu = nn.ReLU()\n",
        "    self.avgPool2d = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    self.maxPool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    # Skip conv\n",
        "    self.conv_skip1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.conv_skip2 = nn.Conv2d(in_channels=35, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.conv_skip3 = nn.Conv2d(in_channels=99, out_channels=256, kernel_size=3, padding=1)\n",
        "\n",
        "    # channel attention\n",
        "    self.adaptivePool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.caconv1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1)\n",
        "    self.caconv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Layer 1\n",
        "    # convolution layers\n",
        "    temp_input = x\n",
        "    out = self.relu(self.conv1_1(x))\n",
        "    out = self.relu(self.conv1_2(out))\n",
        "\n",
        "    # Skip connection\n",
        "    skip = self.relu(self.conv_skip1(temp_input))\n",
        "    out = out + skip\n",
        "\n",
        "    # Dense connection\n",
        "    out = torch.cat([out, temp_input], dim=1)\n",
        "\n",
        "    # Layer 2\n",
        "    # Convolution layers\n",
        "    out = self.maxPool2d(out)\n",
        "    temp_input = out\n",
        "    out = self.relu(self.conv2_1(out))\n",
        "    out = self.relu(self.conv2_2(out))\n",
        "\n",
        "    # Channel attention\n",
        "    ca_out = self.adaptivePool(out)\n",
        "    ca_out = self.caconv1(ca_out)\n",
        "    ca_out = self.relu(ca_out)\n",
        "    ca_out = self.caconv2(ca_out)\n",
        "    ca_out = self.sigmoid(ca_out)\n",
        "    ca_out = ca_out.expand_as(out)\n",
        "    out = out * ca_out\n",
        "\n",
        "    # Skip connection\n",
        "    skip = self.relu(self.conv_skip2(temp_input))\n",
        "    out = out + skip\n",
        "\n",
        "    # Dense connection\n",
        "    out = torch.cat([out, temp_input], dim=1)\n",
        "\n",
        "    # Layer 3\n",
        "    # Convolution layers\n",
        "    out = self.maxPool2d(out)\n",
        "    temp_input = out\n",
        "    out = self.relu(self.conv3_1(out))\n",
        "    out = self.relu(self.conv3_2(out))\n",
        "\n",
        "    # Skip connection\n",
        "    skip = self.relu(self.conv_skip3(temp_input))\n",
        "    out = out + skip\n",
        "    out = self.maxPool2d(out)\n",
        "\n",
        "    # 평탄화\n",
        "    out = out.reshape(-1, 4096)\n",
        "\n",
        "    # fully connected layers\n",
        "    out = self.relu(self.fc1(out))\n",
        "    out = self.relu(self.fc2(out))\n",
        "    out = self.fc3(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "5tOeoDGFsEfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "k6mPJAOusNSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters 지정\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "training_epochs = 20\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "network = CombiNet()\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr = learning_rate)\n",
        "data_loader = DataLoader(dataset=cifar10_train,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True,\n",
        "                         drop_last=True)\n",
        "\n",
        "# 학습을 위한 반복문 진행\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda:0'\n",
        "\n",
        "network = network.to(device)\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "  total_batch = len(data_loader)\n",
        "\n",
        "  for img, label in data_loader:\n",
        "\n",
        "    img = img.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    pred = network(img)\n",
        "\n",
        "    loss = loss_function(pred, label)\n",
        "    optimizer.zero_grad() # gradient 초기화\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += loss / total_batch\n",
        "\n",
        "  print('Epoch: %d Loss = %f'%(epoch+1, avg_cost))\n",
        "\n",
        "print('Learning finished')\n",
        "\n",
        "# 정답률 확인\n",
        "network = network.to('cpu')\n",
        "with torch.no_grad(): # test에서는 기울기 계산 제외\n",
        "\n",
        "  img_test = torch.tensor(np.transpose(cifar10_test.data, (0, 3, 1, 2)))/255.\n",
        "  label_test = torch.tensor(cifar10_test.targets)\n",
        "\n",
        "  prediction = network(img_test) # 전체 test data를 한번에 계산\n",
        "\n",
        "  correct_prediction = torch.argmax(prediction, 1) == label_test\n",
        "  accuracy = correct_prediction.float().mean()\n",
        "  print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "id": "pB9-UKvasMXV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}