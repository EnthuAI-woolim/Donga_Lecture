{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqqGTY_4n-D-"
      },
      "source": [
        "\n",
        "# Multi Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jrov3gjoGJm"
      },
      "source": [
        "## Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2gyfKfgoFqa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7zbSpMPoKyN"
      },
      "source": [
        "## Load datasets\n",
        "\n",
        "- kc_house_data: 미국 워싱턴주 시애틀(South King County)을 포함한 킹카운티(King County) 지역의 주택 가격 데이터를 포함한 공개 데이터셋\n",
        "1. id: 각 주택 거래에 대한 고유 식별자.\n",
        "2. date: 주택이 판매된 날짜.\n",
        "3. price: 주택의 판매 가격 (종속 변수, 목표 값).\n",
        "4. bedrooms: 침실의 개수.\n",
        "5. bathrooms: 욕실의 개수 (부분 욕실도 포함).\n",
        "6. sqft_living: 주택의 실내 면적 (평방 피트).\n",
        "7. sqft_lot: 주택의 대지 면적 (평방 피트).\n",
        "8. floors: 주택의 층수.\n",
        "9. waterfront: 주택이 해안가에 위치해 있는지 여부 (1: 해안가, 0: 해안가 아님).\n",
        "10. view: 주택에서의 전망의 질을 나타내는 지표 (0~4).\n",
        "11. condition: 주택의 전반적인 상태 (1~5).\n",
        "12. grade: 주택의 건축 품질과 디자인 등급 (1~13).\n",
        "13. sqft_above: 지상 층의 면적 (평방 피트).\n",
        "14. sqft_basement: 지하 층의 면적 (평방 피트).\n",
        "15. yr_built: 주택이 지어진 연도.\n",
        "16. yr_renovated: 주택이 개보수된 연도.\n",
        "17. zipcode: 우편번호.\n",
        "18. lat: 주택의 위도.\n",
        "19. long: 주택의 경도.\n",
        "20. sqft_living15: 2015년 기준으로, 인근 15개의 주택의 평균 실내 면적 (평방 피트).\n",
        "21. sqft_lot15: 2015년 기준으로, 인근 15개의 주택의 평균 대지 면적 (평방 피트)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtLmf-OVLUJH"
      },
      "outputs": [],
      "source": [
        "# Dataset 다운로드\n",
        "!wget \"https://dongaackr-my.sharepoint.com/:x:/g/personal/sjkim_donga_ac_kr/ET2udlQfsxRAsvnlEtgzfi0B3HAMAmqP_Y2WRsbYrTvYaA?e=t6809f&download=1\" -O kc_house_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dsTsL0toCH5"
      },
      "outputs": [],
      "source": [
        "# Load dataset file\n",
        "data = pd.read_csv('kc_house_data.csv')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZo4gYJI4bxK"
      },
      "source": [
        "## Dataset 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwvdr81v4bxK"
      },
      "outputs": [],
      "source": [
        "# 예측 수행에 불필요한 열 삭제\n",
        "new_data = data.drop(['id', 'date'], axis=1)\n",
        "\n",
        "# 값이 존재하지 않는 행 삭제\n",
        "new_data = new_data.dropna()\n",
        "\n",
        "# 데이터셋 가우시안 정규화\n",
        "data_normalized = (new_data - new_data.mean()) / new_data.std()\n",
        "data_normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x00Ge0jc4bxL"
      },
      "source": [
        "## Dataset 특성 파악"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtAJtdGv4bxM"
      },
      "outputs": [],
      "source": [
        "# 각 데이터에 대한 시각화\n",
        "fixed_column = 'price'\n",
        "used_columns = data_normalized.columns.drop(fixed_column)\n",
        "\n",
        "num_vars = len(used_columns)\n",
        "rows = (num_vars + 2) // 3  # 3열 기준으로 필요한 행 계산\n",
        "\n",
        "fig, axs = plt.subplots(rows, 3, figsize=(15, rows * 5))\n",
        "\n",
        "# 각 열에 대해 scatter plot을 생성하는 반복문\n",
        "for i, used_column in enumerate(used_columns):\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "    axs[row, col].scatter(data_normalized[used_column], data_normalized[fixed_column], color='blue')\n",
        "    axs[row, col].set_title(f'{used_column} vs {fixed_column}')\n",
        "    axs[row, col].set_xlabel(used_column)\n",
        "    axs[row, col].set_ylabel(fixed_column)\n",
        "\n",
        "# 남은 빈 subplot 제거\n",
        "for i in range(num_vars, rows * 3):\n",
        "    fig.delaxes(axs.flatten()[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tujWgGGZ4bxN"
      },
      "outputs": [],
      "source": [
        "# 데이터의 각 열에 대한 상관관계 확인\n",
        "correlation_matrix = data_normalized.corr()\n",
        "correlation_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur2WWoTp4bxN"
      },
      "source": [
        "## 집 가격 예측에 사용할 데이터 지정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWKJdELRoyoL"
      },
      "outputs": [],
      "source": [
        "# 예측에 사용할 데이터들에 대한 2차원 행렬 변환\n",
        "x = np.array(data_normalized[['sqft_living']])\n",
        "y = np.array(data_normalized[['price']])\n",
        "\n",
        "# Train dataset / Test dataset 분할\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# Train dataset 형상 확인\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdRt-Dqcxo4R"
      },
      "source": [
        "## Single Layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2epOKJlpBW8"
      },
      "outputs": [],
      "source": [
        "class SLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SLP, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(1, 1, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = self.fc1(x)\n",
        "\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AgWiUhpyIoW"
      },
      "source": [
        "## Hyper-parameters 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Biugiy9uyNCT"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "learning_rate = 0.01\n",
        "training_epochs = 50\n",
        "loss_function = nn.MSELoss()\n",
        "network = SLP()\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS2Nm0RTybet"
      },
      "source": [
        "## Perceptron 학습을 위한 반복문 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmaOQBm0ydEM"
      },
      "outputs": [],
      "source": [
        "network.train()\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "  total_batch = len(x_train) // batch_size\n",
        "\n",
        "  for batch in range(total_batch):\n",
        "    input = torch.tensor(x_train[batch * batch_size : (batch * batch_size) + batch_size, :], dtype=torch.float32)\n",
        "    label = torch.tensor(y_train[batch * batch_size : (batch * batch_size) + batch_size, :], dtype=torch.float32)\n",
        "\n",
        "    pred = network(input)\n",
        "\n",
        "    loss = loss_function(pred, label)\n",
        "    optimizer.zero_grad() # gradient 초기화\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += loss / total_batch\n",
        "\n",
        "  print('Epoch: %d Loss = %f'%(epoch+1, avg_cost))\n",
        "\n",
        "print('Learning finished')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4nLALj22MxJ"
      },
      "outputs": [],
      "source": [
        "for param in network.parameters():\n",
        "    print(param)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LGc0CcQ2ZJ_"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEsxPtQqzwbU"
      },
      "outputs": [],
      "source": [
        "# Test dataset을 이용한 예측\n",
        "input = torch.tensor(x_test, dtype=torch.float32)\n",
        "network.eval()\n",
        "with torch.no_grad(): # test에서는 기울기 계산 제외\n",
        "    y_hat = network(input)\n",
        "y_hat = y_hat.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSGUo6jI4bxQ"
      },
      "outputs": [],
      "source": [
        "# 정답 데이터와 예측 데이터 간 차이 계산\n",
        "def MSE (pred, label):\n",
        "  error = pred - label\n",
        "  mse = np.mean(error ** 2)\n",
        "  return mse\n",
        "\n",
        "print(MSE(y_hat, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0qZlF1o4bxQ"
      },
      "outputs": [],
      "source": [
        "# 시각화\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "plt.scatter(x_test, y_test, color='b', marker='o', s=30)\n",
        "plt.plot(x_test, y_hat, color='r')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch-gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
